{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1X8wxjpMd2IOez-Sfc26tPUjOE3_71uio","timestamp":1696613454390}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"glOktcvb1-k5","executionInfo":{"status":"ok","timestamp":1696613504919,"user_tz":-330,"elapsed":22486,"user":{"displayName":"Mayur Btech","userId":"03897252125906617679"}},"outputId":"b46b6edb-1e06-4b02-f029-576d5a3d87a0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWUQg4XEsas5","executionInfo":{"status":"ok","timestamp":1696613557570,"user_tz":-330,"elapsed":1177,"user":{"displayName":"Mayur Btech","userId":"03897252125906617679"}},"outputId":"838043bb-426b-4ae2-de86-59588ed8b594"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0\n"," 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0\n"," 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1]\n","Accuracy: 1.0\n"]}],"source":["#Decision tree\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n","\n","classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n","classifier.fit(X_train, y_train)\n","\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)"]},{"cell_type":"code","source":["#Random forest\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","\n","classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n","classifier.fit(X_train, y_train)\n","\n","\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmq1DkrdtyNk","executionInfo":{"status":"ok","timestamp":1696613571794,"user_tz":-330,"elapsed":667,"user":{"displayName":"Mayur Btech","userId":"03897252125906617679"}},"outputId":"2e583939-6ec9-4ff6-c076-abdad80c1858"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0\n"," 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0\n"," 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1\n"," 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1\n"," 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1\n"," 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1]\n","Accuracy: 1.0\n"]}]},{"cell_type":"code","source":["#SVM\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","\n","classifier = SVC(kernel='linear', random_state=0)\n","classifier.fit(X_train, y_train)\n","\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x92g2cfduAFT","executionInfo":{"status":"ok","timestamp":1696613581898,"user_tz":-330,"elapsed":2764,"user":{"displayName":"Mayur Btech","userId":"03897252125906617679"}},"outputId":"fc6f0d37-099d-461c-a43d-2f8b1d612c9a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1\n"," 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0\n"," 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1\n"," 1 0 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0\n"," 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1\n"," 0 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1]\n","Accuracy: 0.8390243902439024\n"]}]},{"cell_type":"code","source":["#logistic regression\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","\n","classifier = LogisticRegression(random_state=0)\n","classifier.fit(X_train, y_train)\n","\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSyOL6AWuFbT","executionInfo":{"status":"ok","timestamp":1696613595026,"user_tz":-330,"elapsed":415,"user":{"displayName":"Mayur Btech","userId":"03897252125906617679"}},"outputId":"ea4c9576-9be1-4b35-a261-ebb1a112ba0b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1\n"," 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0\n"," 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1\n"," 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0\n"," 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1\n"," 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1]\n","Accuracy: 0.8634146341463415\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}]},{"cell_type":"code","source":["#KNN\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","classifier = KNeighborsClassifier(n_neighbors=5)\n","classifier.fit(X_train, y_train)\n","\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajadWBr4vJ9S","executionInfo":{"status":"ok","timestamp":1696613605140,"user_tz":-330,"elapsed":393,"user":{"displayName":"Mayur Btech","userId":"03897252125906617679"}},"outputId":"67a67863-5cd2-445f-8603-1d19c904c6a8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1\n"," 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0\n"," 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0\n"," 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1\n"," 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n"," 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1]\n","Accuracy: 0.7463414634146341\n"]}]},{"cell_type":"code","source":["#Naive bayes\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","\n","data = pd.read_csv('/content/drive/MyDrive/heart.csv')\n","\n","\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","classifier = GaussianNB()\n","classifier.fit(X_train, y_train)\n","\n","y_pred = classifier.predict(X_test)\n","print(y_pred)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7xEYm1Rvffp","executionInfo":{"status":"ok","timestamp":1696613613927,"user_tz":-330,"elapsed":18,"user":{"displayName":"Mayur Btech","userId":"03897252125906617679"}},"outputId":"8a9c1bfc-c6c5-47bd-d1b5-f695a9e94750"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0\n"," 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0\n"," 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1\n"," 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0\n"," 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1\n"," 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1]\n","Accuracy: 0.8536585365853658\n"]}]},{"cell_type":"markdown","source":["Deep Learning"],"metadata":{"id":"xS5SxCxVSwGJ"}},{"cell_type":"code","source":["#DNN\n","# Import required libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","# Import necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# Keras specific\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv\")\n","x=df.drop('target',axis=1)\n","y=df['target']\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n","model = Sequential()\n","model.add(Dense(500, activation='relu', input_dim=13))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(x_train,y_train, epochs=200)\n","loss, accuracy = model.evaluate(x_test, y_test)\n","\n","print('Accuracy:', accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I2vUPMs6Sy83","executionInfo":{"status":"ok","timestamp":1696613651043,"user_tz":-330,"elapsed":25688,"user":{"displayName":"Mayur Btech","userId":"03897252125906617679"}},"outputId":"02f265c0-54d8-478e-c208-29227e9dfff5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","24/24 [==============================] - 1s 4ms/step - loss: 1.3926 - accuracy: 0.5208\n","Epoch 2/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6042\n","Epoch 3/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6576\n","Epoch 4/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6602\n","Epoch 5/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6849\n","Epoch 6/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7214\n","Epoch 7/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7318\n","Epoch 8/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7161\n","Epoch 9/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7305\n","Epoch 10/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6732\n","Epoch 11/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7435\n","Epoch 12/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7227\n","Epoch 13/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7526\n","Epoch 14/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.7266\n","Epoch 15/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7669\n","Epoch 16/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8034\n","Epoch 17/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7839\n","Epoch 18/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7786\n","Epoch 19/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8294\n","Epoch 20/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8333\n","Epoch 21/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8333\n","Epoch 22/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8555\n","Epoch 23/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8216\n","Epoch 24/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8099\n","Epoch 25/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8294\n","Epoch 26/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8099\n","Epoch 27/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7956\n","Epoch 28/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8177\n","Epoch 29/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8464\n","Epoch 30/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8529\n","Epoch 31/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8581\n","Epoch 32/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8359\n","Epoch 33/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8581\n","Epoch 34/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8164\n","Epoch 35/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8659\n","Epoch 36/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8398\n","Epoch 37/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8112\n","Epoch 38/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8229\n","Epoch 39/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8398\n","Epoch 40/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8073\n","Epoch 41/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8242\n","Epoch 42/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8451\n","Epoch 43/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8151\n","Epoch 44/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8372\n","Epoch 45/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8594\n","Epoch 46/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8464\n","Epoch 47/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7982\n","Epoch 48/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8099\n","Epoch 49/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8646\n","Epoch 50/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8620\n","Epoch 51/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8529\n","Epoch 52/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8333\n","Epoch 53/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8672\n","Epoch 54/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8594\n","Epoch 55/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8242\n","Epoch 56/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8516\n","Epoch 57/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8307\n","Epoch 58/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8594\n","Epoch 59/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8568\n","Epoch 60/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8529\n","Epoch 61/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8633\n","Epoch 62/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8594\n","Epoch 63/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8646\n","Epoch 64/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.8750\n","Epoch 65/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8633\n","Epoch 66/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8698\n","Epoch 67/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8737\n","Epoch 68/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8724\n","Epoch 69/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8763\n","Epoch 70/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8555\n","Epoch 71/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8464\n","Epoch 72/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8672\n","Epoch 73/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8646\n","Epoch 74/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8750\n","Epoch 75/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8724\n","Epoch 76/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8711\n","Epoch 77/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8672\n","Epoch 78/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8372\n","Epoch 79/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8555\n","Epoch 80/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8646\n","Epoch 81/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8815\n","Epoch 82/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8802\n","Epoch 83/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8685\n","Epoch 84/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8477\n","Epoch 85/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8620\n","Epoch 86/200\n","24/24 [==============================] - 0s 6ms/step - loss: 0.3184 - accuracy: 0.8659\n","Epoch 87/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8763\n","Epoch 88/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8724\n","Epoch 89/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8763\n","Epoch 90/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8581\n","Epoch 91/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8750\n","Epoch 92/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.8867\n","Epoch 93/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8802\n","Epoch 94/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8802\n","Epoch 95/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8607\n","Epoch 96/200\n","24/24 [==============================] - 0s 7ms/step - loss: 0.3050 - accuracy: 0.8685\n","Epoch 97/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8529\n","Epoch 98/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8789\n","Epoch 99/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8555\n","Epoch 100/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8659\n","Epoch 101/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8711\n","Epoch 102/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8828\n","Epoch 103/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8815\n","Epoch 104/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8685\n","Epoch 105/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.8932\n","Epoch 106/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8620\n","Epoch 107/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8802\n","Epoch 108/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8802\n","Epoch 109/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.8854\n","Epoch 110/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2810 - accuracy: 0.8919\n","Epoch 111/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.8776\n","Epoch 112/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8971\n","Epoch 113/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.8893\n","Epoch 114/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8776\n","Epoch 115/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8789\n","Epoch 116/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8854\n","Epoch 117/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.8685\n","Epoch 118/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8880\n","Epoch 119/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8880\n","Epoch 120/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8737\n","Epoch 121/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8815\n","Epoch 122/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.8776\n","Epoch 123/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8789\n","Epoch 124/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8867\n","Epoch 125/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8828\n","Epoch 126/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8919\n","Epoch 127/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8958\n","Epoch 128/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8893\n","Epoch 129/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.8880\n","Epoch 130/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8750\n","Epoch 131/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8971\n","Epoch 132/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8867\n","Epoch 133/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8776\n","Epoch 134/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8828\n","Epoch 135/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.8971\n","Epoch 136/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.8880\n","Epoch 137/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8841\n","Epoch 138/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8867\n","Epoch 139/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8737\n","Epoch 140/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.8971\n","Epoch 141/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.8828\n","Epoch 142/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8542\n","Epoch 143/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8646\n","Epoch 144/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.8984\n","Epoch 145/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8685\n","Epoch 146/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8750\n","Epoch 147/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8594\n","Epoch 148/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8815\n","Epoch 149/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8893\n","Epoch 150/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.8945\n","Epoch 151/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8841\n","Epoch 152/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.8867\n","Epoch 153/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.9023\n","Epoch 154/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8945\n","Epoch 155/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9010\n","Epoch 156/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9036\n","Epoch 157/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8542\n","Epoch 158/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8659\n","Epoch 159/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8542\n","Epoch 160/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.8763\n","Epoch 161/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8789\n","Epoch 162/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9049\n","Epoch 163/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8919\n","Epoch 164/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.9010\n","Epoch 165/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.9036\n","Epoch 166/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8919\n","Epoch 167/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.8828\n","Epoch 168/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8984\n","Epoch 169/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9128\n","Epoch 170/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.8932\n","Epoch 171/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9102\n","Epoch 172/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.9180\n","Epoch 173/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9089\n","Epoch 174/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9089\n","Epoch 175/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9193\n","Epoch 176/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9258\n","Epoch 177/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.9076\n","Epoch 178/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9219\n","Epoch 179/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.8932\n","Epoch 180/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8971\n","Epoch 181/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.1904 - accuracy: 0.9297\n","Epoch 182/200\n","24/24 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.9076\n","Epoch 183/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.8906\n","Epoch 184/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1973 - accuracy: 0.9154\n","Epoch 185/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1931 - accuracy: 0.9219\n","Epoch 186/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9193\n","Epoch 187/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9323\n","Epoch 188/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9505\n","Epoch 189/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9349\n","Epoch 190/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.8945\n","Epoch 191/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2677 - accuracy: 0.8880\n","Epoch 192/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9154\n","Epoch 193/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9271\n","Epoch 194/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2224 - accuracy: 0.8997\n","Epoch 195/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9102\n","Epoch 196/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9128\n","Epoch 197/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9427\n","Epoch 198/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9518\n","Epoch 199/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9388\n","Epoch 200/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9349\n","9/9 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.8872\n","Accuracy: 0.887159526348114\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"krGC5eZbDWol"},"execution_count":null,"outputs":[]}]}